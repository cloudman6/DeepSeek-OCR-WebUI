# ğŸš€ GPU æ™ºèƒ½ç®¡ç† - å¿«é€Ÿå¼€å§‹

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- âœ… **æ‡’åŠ è½½**ï¼šé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åŠ è½½æ¨¡å‹ï¼ˆ20-30ç§’ï¼‰
- âœ… **å³ç”¨å³å¸**ï¼šä»»åŠ¡å®Œæˆåç«‹å³é‡Šæ”¾æ˜¾å­˜ï¼ˆ2ç§’ï¼‰
- âœ… **CPU ç¼“å­˜**ï¼šæ¨¡å‹åœ¨ CPU å’Œ GPU ä¹‹é—´å¿«é€Ÿåˆ‡æ¢ï¼ˆ2-5ç§’ï¼‰
- âœ… **è‡ªåŠ¨é€‰æ‹©**ï¼šå¯åŠ¨æ—¶è‡ªåŠ¨é€‰æ‹©æœ€ç©ºé—²çš„ GPU
- âœ… **è‡ªåŠ¨ç›‘æ§**ï¼šç©ºé—²è¶…æ—¶åè‡ªåŠ¨å¸è½½åˆ° CPU

---

## ğŸ¯ ä¸€é”®å¯åŠ¨

```bash
./start_gpu.sh
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
==================================================
ğŸš€ DeepSeek-OCR with GPU Management
==================================================
âœ… NVIDIA Docker environment OK

ğŸ” Detecting available GPUs...
0, NVIDIA L40S, 22331 MiB, 46068 MiB
1, NVIDIA L40S, 433 MiB, 46068 MiB
2, NVIDIA L40S, 3 MiB, 46068 MiB  â† è‡ªåŠ¨é€‰æ‹©
3, NVIDIA L40S, 3 MiB, 46068 MiB

âœ… Selected GPU 2: NVIDIA L40S
   Memory: 3MB / 46068MB used

ğŸ“ Access URLs:
   - Local:  http://localhost:8001
   - Remote: http://192.168.1.100:8001
```

---

## ğŸ“Š å·¥ä½œæµç¨‹

### çŠ¶æ€è½¬æ¢å›¾

```
æœªåŠ è½½ â”€â”€é¦–æ¬¡è¯·æ±‚(20-30s)â”€â”€â†’ GPU â”€â”€ä»»åŠ¡å®Œæˆ(2s)â”€â”€â†’ CPU â”€â”€æ–°è¯·æ±‚(2-5s)â”€â”€â†’ GPU
  â†‘                                                      â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€è¶…æ—¶/æ‰‹åŠ¨é‡Šæ”¾(1s)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ˜¾å­˜å ç”¨

| é˜¶æ®µ | ä¼ ç»Ÿæ–¹å¼ | GPU ç®¡ç† | èŠ‚çœ |
|------|---------|---------|------|
| ç©ºé—²æ—¶ | ~7 GB | < 1 GB | ~6 GB |
| å¤„ç†ä¸­ | ~7 GB | ~7 GB | 0 GB |
| å¤„ç†å | ~7 GB | < 1 GB | ~6 GB |

---

## ğŸ”§ API ç«¯ç‚¹

### 1. å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8001/health
```

**å“åº”**ï¼š
```json
{
  "status": "healthy",
  "backend": "cuda",
  "platform": "Linux",
  "gpu_manager": true,
  "model_location": "unloaded",
  "idle_time": 0,
  "device": "cuda",
  "timeout": 60,
  "gpu_memory_allocated": 0.0,
  "gpu_memory_reserved": 0.0
}
```

### 2. GPU çŠ¶æ€

```bash
curl http://localhost:8001/gpu/status
```

**å“åº”**ï¼š
```json
{
  "model_location": "cpu",
  "idle_time": 45.2,
  "device": "cuda",
  "timeout": 60,
  "gpu_memory_allocated": 0.5,
  "gpu_memory_reserved": 2.0
}
```

### 3. æ‰‹åŠ¨å¸è½½

```bash
curl -X POST http://localhost:8001/gpu/offload
```

**ä½œç”¨**ï¼šç«‹å³å°†æ¨¡å‹ä» GPU è½¬ç§»åˆ° CPU

### 4. å®Œå…¨é‡Šæ”¾

```bash
curl -X POST http://localhost:8001/gpu/release
```

**ä½œç”¨**ï¼šæ¸…ç©º GPU å’Œ CPU ç¼“å­˜

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
./test_gpu_management.sh
```

### æ‰‹åŠ¨æµ‹è¯•

```bash
# 1. æŸ¥çœ‹åˆå§‹çŠ¶æ€
curl http://localhost:8001/gpu/status

# 2. ä¸Šä¼ å›¾ç‰‡è¿›è¡Œ OCRï¼ˆé€šè¿‡ Web UIï¼‰
# è®¿é—® http://localhost:8001

# 3. æŸ¥çœ‹å¤„ç†åçŠ¶æ€ï¼ˆåº”è¯¥æ˜¯ cpuï¼‰
curl http://localhost:8001/gpu/status

# 4. ç›‘æ§ GPU æ˜¾å­˜
watch -n 1 nvidia-smi
```

---

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

### å“åº”æ—¶é—´

| åœºæ™¯ | æ—¶é—´ | è¯´æ˜ |
|------|------|------|
| é¦–æ¬¡è¯·æ±‚ | 20-30s | ä»ç£ç›˜åŠ è½½æ¨¡å‹ |
| åç»­è¯·æ±‚ï¼ˆGPUï¼‰ | < 1s | æ¨¡å‹å·²åœ¨ GPU |
| åç»­è¯·æ±‚ï¼ˆCPU ç¼“å­˜ï¼‰ | 2-5s | ä» CPU æ¢å¤åˆ° GPU |
| å¸è½½åˆ° CPU | ~2s | é‡Šæ”¾ GPU æ˜¾å­˜ |
| å®Œå…¨é‡Šæ”¾ | ~1s | æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ |

### æ˜¾å­˜èŠ‚çœ

- **ç©ºé—²æ—¶èŠ‚çœ**ï¼š~6 GBï¼ˆ85%ï¼‰
- **å¤šæœåŠ¡å…±äº«**ï¼šå¯åœ¨åŒä¸€ GPU ä¸Šè¿è¡Œæ›´å¤šæœåŠ¡
- **æˆæœ¬ä¼˜åŒ–**ï¼šå‡å°‘ GPU èµ„æºæµªè´¹

---

## âš™ï¸ é…ç½®

### ç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰

```bash
# æœåŠ¡ç«¯å£
PORT=8001

# GPU IDï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ç©ºé—²çš„ï¼‰
NVIDIA_VISIBLE_DEVICES=2

# GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰
GPU_IDLE_TIMEOUT=60
```

### è¶…æ—¶å»ºè®®

| ä½¿ç”¨é¢‘ç‡ | è¶…æ—¶æ—¶é—´ | è¯´æ˜ |
|---------|---------|------|
| é«˜é¢‘ï¼ˆæ¯åˆ†é’Ÿå¤šæ¬¡ï¼‰ | 30-60s | å¿«é€Ÿå“åº” |
| ä¸­é¢‘ï¼ˆæ¯å°æ—¶æ•°æ¬¡ï¼‰ | 120-300s | å¹³è¡¡æ€§èƒ½ |
| ä½é¢‘ï¼ˆæ¯å¤©æ•°æ¬¡ï¼‰ | 600s+ | æœ€å¤§èŠ‚çœ |

---

## ğŸ” ç›‘æ§

### å®æ—¶ç›‘æ§ GPU

```bash
# æ–¹æ³•1: nvidia-smi
watch -n 1 nvidia-smi

# æ–¹æ³•2: åªçœ‹æ˜¾å­˜
watch -n 1 'nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv'

# æ–¹æ³•3: æŸ¥çœ‹æŒ‡å®š GPU
nvidia-smi -i 2
```

### æŸ¥çœ‹æœåŠ¡æ—¥å¿—

```bash
# å®æ—¶æ—¥å¿—
docker logs -f deepseek-ocr-gpu

# æœ€è¿‘ 50 è¡Œ
docker logs --tail 50 deepseek-ocr-gpu

# æœç´¢å…³é”®è¯
docker logs deepseek-ocr-gpu 2>&1 | grep "GPU\|offload\|load"
```

---

## ğŸ› ï¸ ç®¡ç†å‘½ä»¤

### æœåŠ¡ç®¡ç†

```bash
# å¯åŠ¨æœåŠ¡
./start_gpu.sh

# åœæ­¢æœåŠ¡
docker compose -f docker-compose.gpu.yml down

# é‡å¯æœåŠ¡
docker compose -f docker-compose.gpu.yml restart

# æŸ¥çœ‹çŠ¶æ€
docker ps | grep deepseek-ocr-gpu
```

### GPU ç®¡ç†

```bash
# æ‰‹åŠ¨å¸è½½ GPU
curl -X POST http://localhost:8001/gpu/offload

# å®Œå…¨é‡Šæ”¾èµ„æº
curl -X POST http://localhost:8001/gpu/release

# æŸ¥çœ‹ GPU çŠ¶æ€
curl http://localhost:8001/gpu/status
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1: ç«¯å£è¢«å ç”¨

**ç—‡çŠ¶**ï¼š`address already in use`

**è§£å†³**ï¼š
```bash
# æŸ¥æ‰¾å ç”¨è¿›ç¨‹
sudo lsof -i :8001

# åœæ­¢è¿›ç¨‹
kill <PID>

# é‡æ–°å¯åŠ¨
./start_gpu.sh
```

### é—®é¢˜2: GPU æœªè¯†åˆ«

**ç—‡çŠ¶**ï¼š`backend: cpu`

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ Docker GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# é‡å¯ Docker
sudo systemctl restart docker
```

### é—®é¢˜3: æ˜¾å­˜æœªé‡Šæ”¾

**ç—‡çŠ¶**ï¼šGPU æ˜¾å­˜æŒç»­å ç”¨

**è§£å†³**ï¼š
```bash
# æ‰‹åŠ¨å¸è½½
curl -X POST http://localhost:8001/gpu/offload

# å®Œå…¨é‡Šæ”¾
curl -X POST http://localhost:8001/gpu/release

# é‡å¯å®¹å™¨
docker restart deepseek-ocr-gpu
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [GPU ç®¡ç†è¯¦ç»†æ–‡æ¡£](./GPU_MANAGEMENT.md)
- [å®Œæ•´ README](./README.md)
- [éƒ¨ç½²æ€»ç»“](./DEPLOYMENT_SUMMARY.md)

---

## ğŸ¯ æœ€ä½³å®è·µ

### ç”Ÿäº§ç¯å¢ƒ

```bash
# 1. è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
GPU_IDLE_TIMEOUT=300

# 2. å¯ç”¨å¥åº·æ£€æŸ¥
docker compose -f docker-compose.gpu.yml up -d

# 3. é…ç½®ç›‘æ§å‘Šè­¦
# ç›‘æ§ GPU æ˜¾å­˜å ç”¨ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶å‘Šè­¦
```

### å¼€å‘ç¯å¢ƒ

```bash
# 1. è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
GPU_IDLE_TIMEOUT=30

# 2. æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker logs -f deepseek-ocr-gpu

# 3. ç›‘æ§ GPU çŠ¶æ€
watch -n 1 nvidia-smi
```

### å¤š GPU ç¯å¢ƒ

```bash
# æ–¹æ³•1: æ‰‹åŠ¨æŒ‡å®š GPU
NVIDIA_VISIBLE_DEVICES=1 ./start_gpu.sh

# æ–¹æ³•2: ä¿®æ”¹ .env
echo "NVIDIA_VISIBLE_DEVICES=1" > .env
docker compose -f docker-compose.gpu.yml up -d

# æ–¹æ³•3: è¿è¡Œå¤šä¸ªå®ä¾‹ï¼ˆä¸åŒç«¯å£ï¼‰
PORT=8002 NVIDIA_VISIBLE_DEVICES=1 docker compose -f docker-compose.gpu.yml up -d
```

---

**Made with â¤ï¸ by DeepSeek-OCR Team**
