# ğŸ¯ GPU æ™ºèƒ½ç®¡ç†æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

DeepSeek-OCR ç°å·²æ”¯æŒ GPU æ™ºèƒ½ç®¡ç†ï¼Œå®ç°ï¼š
- âœ… **æ‡’åŠ è½½**ï¼šé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åŠ è½½æ¨¡å‹
- âœ… **å³ç”¨å³å¸**ï¼šä»»åŠ¡å®Œæˆåç«‹å³é‡Šæ”¾æ˜¾å­˜
- âœ… **è‡ªåŠ¨é€‰æ‹©**ï¼šå¯åŠ¨æ—¶è‡ªåŠ¨é€‰æ‹©æœ€ç©ºé—²çš„ GPU
- âœ… **CPU ç¼“å­˜**ï¼šæ¨¡å‹åœ¨ CPU å’Œ GPU ä¹‹é—´å¿«é€Ÿåˆ‡æ¢

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä¸€é”®å¯åŠ¨

```bash
./start_gpu.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. æ£€æŸ¥ nvidia-docker ç¯å¢ƒ
2. æ‰«ææ‰€æœ‰ GPUï¼Œé€‰æ‹©æ˜¾å­˜å ç”¨æœ€å°‘çš„
3. åˆ›å»º `.env` é…ç½®æ–‡ä»¶
4. å¯åŠ¨ Docker å®¹å™¨

---

## ğŸ”§ å·¥ä½œåŸç†

### çŠ¶æ€è½¬æ¢

```
æœªåŠ è½½ â”€â”€é¦–æ¬¡è¯·æ±‚(20-30s)â”€â”€â†’ GPU â”€â”€ä»»åŠ¡å®Œæˆ(2s)â”€â”€â†’ CPU â”€â”€æ–°è¯·æ±‚(2-5s)â”€â”€â†’ GPU
  â†‘                                                      â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€è¶…æ—¶/æ‰‹åŠ¨é‡Šæ”¾(1s)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸‰ç§çŠ¶æ€

| çŠ¶æ€ | ä½ç½® | æ˜¾å­˜å ç”¨ | åˆ‡æ¢æ—¶é—´ |
|------|------|----------|----------|
| **æœªåŠ è½½** | ç£ç›˜ | 0 MB | é¦–æ¬¡åŠ è½½ 20-30s |
| **GPU** | GPU | ~7 GB | ç«‹å³å¯ç”¨ |
| **CPU ç¼“å­˜** | CPU | 0 MB (GPU) | æ¢å¤åˆ° GPU 2-5s |

---

## ğŸ“Š API ç«¯ç‚¹

### 1. å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8001/health
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "status": "healthy",
  "backend": "cuda",
  "platform": "Linux",
  "gpu_manager": true,
  "model_location": "cpu",
  "idle_time": 45.2,
  "device": "cuda",
  "timeout": 60,
  "gpu_memory_allocated": 0.5,
  "gpu_memory_reserved": 2.0
}
```

### 2. GPU çŠ¶æ€æŸ¥è¯¢

```bash
curl http://localhost:8001/gpu/status
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "model_location": "cpu",
  "idle_time": 120.5,
  "device": "cuda",
  "timeout": 60,
  "gpu_memory_allocated": 0.5,
  "gpu_memory_reserved": 2.0
}
```

### 3. æ‰‹åŠ¨å¸è½½ GPU

```bash
curl -X POST http://localhost:8001/gpu/offload
```

**ä½œç”¨**ï¼šç«‹å³å°†æ¨¡å‹ä» GPU è½¬ç§»åˆ° CPUï¼Œé‡Šæ”¾æ˜¾å­˜

### 4. å®Œå…¨é‡Šæ”¾èµ„æº

```bash
curl -X POST http://localhost:8001/gpu/release
```

**ä½œç”¨**ï¼šæ¸…ç©º GPU å’Œ CPU ç¼“å­˜ï¼Œå®Œå…¨é‡Šæ”¾å†…å­˜

---

## âš™ï¸ é…ç½®å‚æ•°

### ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ï¼š

```bash
# æœåŠ¡ç«¯å£
PORT=8001

# GPU IDï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
NVIDIA_VISIBLE_DEVICES=0

# GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰
GPU_IDLE_TIMEOUT=60

# å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šåç«¯ï¼ˆå¯é€‰ï¼‰
# FORCE_BACKEND=cuda
```

### è¶…æ—¶é…ç½®

| è¶…æ—¶æ—¶é—´ | é€‚ç”¨åœºæ™¯ |
|---------|---------|
| 30-60s | é¢‘ç¹ä½¿ç”¨ï¼ˆæ¨èï¼‰ |
| 120-300s | ä¸­ç­‰é¢‘ç‡ |
| 600s+ | ä½é¢‘ä½¿ç”¨ |

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### 1. æ£€æŸ¥å®¹å™¨çŠ¶æ€

```bash
docker ps | grep deepseek-ocr-gpu
```

### 2. æŸ¥çœ‹æ—¥å¿—

```bash
docker logs -f deepseek-ocr-gpu
```

### 3. æµ‹è¯• OCR

```bash
curl -X POST http://localhost:8001/ocr \
  -F "file=@test.png" \
  -F "prompt_type=document"
```

### 4. ç›‘æ§ GPU æ˜¾å­˜

```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æŸ¥çœ‹æŒ‡å®š GPU
nvidia-smi -i 0 --query-gpu=memory.used,memory.total --format=csv
```

### 5. éªŒè¯æ‡’åŠ è½½

```bash
# æ­¥éª¤1: æŸ¥çœ‹åˆå§‹çŠ¶æ€ï¼ˆåº”è¯¥æ˜¯ unloadedï¼‰
curl http://localhost:8001/gpu/status

# æ­¥éª¤2: å‘é€ OCR è¯·æ±‚
curl -X POST http://localhost:8001/ocr -F "file=@test.png"

# æ­¥éª¤3: ç«‹å³æŸ¥çœ‹çŠ¶æ€ï¼ˆåº”è¯¥æ˜¯ cpuï¼Œå› ä¸ºå·²å¸è½½ï¼‰
curl http://localhost:8001/gpu/status

# æ­¥éª¤4: ç­‰å¾…è¶…æ—¶åæŸ¥çœ‹ï¼ˆåº”è¯¥è¿˜æ˜¯ cpuï¼‰
sleep 70
curl http://localhost:8001/gpu/status
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### æ˜¾å­˜å ç”¨

| é˜¶æ®µ | ä¼ ç»Ÿæ–¹å¼ | GPU ç®¡ç† | èŠ‚çœ |
|------|---------|---------|------|
| ç©ºé—²æ—¶ | ~7 GB | < 1 GB | ~6 GB |
| å¤„ç†ä¸­ | ~7 GB | ~7 GB | 0 GB |
| å¤„ç†å | ~7 GB | < 1 GB | ~6 GB |

### å“åº”æ—¶é—´

| åœºæ™¯ | æ—¶é—´ | è¯´æ˜ |
|------|------|------|
| é¦–æ¬¡è¯·æ±‚ | 20-30s | ä»ç£ç›˜åŠ è½½æ¨¡å‹ |
| åç»­è¯·æ±‚ï¼ˆGPUï¼‰ | < 1s | æ¨¡å‹å·²åœ¨ GPU |
| åç»­è¯·æ±‚ï¼ˆCPU ç¼“å­˜ï¼‰ | 2-5s | ä» CPU æ¢å¤åˆ° GPU |

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1: GPU æœªè¢«è¯†åˆ«

**ç—‡çŠ¶**ï¼šæ—¥å¿—æ˜¾ç¤º "CPU mode"

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ Docker GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# é‡å¯ Docker
sudo systemctl restart docker
```

### é—®é¢˜2: æ˜¾å­˜æœªé‡Šæ”¾

**ç—‡çŠ¶**ï¼š`gpu/status` æ˜¾ç¤º GPU å ç”¨é«˜

**è§£å†³**ï¼š
```bash
# æ‰‹åŠ¨å¸è½½
curl -X POST http://localhost:8001/gpu/offload

# å®Œå…¨é‡Šæ”¾
curl -X POST http://localhost:8001/gpu/release

# é‡å¯å®¹å™¨
docker restart deepseek-ocr-gpu
```

### é—®é¢˜3: æ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶**ï¼šé¦–æ¬¡è¯·æ±‚è¶…æ—¶

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥æ¨¡å‹ç¼“å­˜
ls -lh ./models/hub/models--deepseek-ai--DeepSeek-OCR/

# æ¸…ç©ºç¼“å­˜é‡æ–°ä¸‹è½½
rm -rf ./models/hub/models--deepseek-ai--DeepSeek-OCR/
docker restart deepseek-ocr-gpu
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ç”Ÿäº§ç¯å¢ƒ

```bash
# è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
GPU_IDLE_TIMEOUT=300

# å¯ç”¨å¥åº·æ£€æŸ¥
docker compose -f docker-compose.gpu.yml up -d
```

### 2. å¼€å‘ç¯å¢ƒ

```bash
# è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
GPU_IDLE_TIMEOUT=30

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker logs -f deepseek-ocr-gpu
```

### 3. å¤š GPU ç¯å¢ƒ

```bash
# æ–¹æ³•1: æ‰‹åŠ¨æŒ‡å®š GPU
NVIDIA_VISIBLE_DEVICES=1 ./start_gpu.sh

# æ–¹æ³•2: ä¿®æ”¹ .env
echo "NVIDIA_VISIBLE_DEVICES=1" > .env
docker compose -f docker-compose.gpu.yml up -d
```

---

## ğŸ“ æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æŸ¥çœ‹æ—¥å¿—ï¼š`docker logs deepseek-ocr-gpu`
2. æ£€æŸ¥ GPUï¼š`nvidia-smi`
3. æäº¤ Issueï¼š[GitHub Issues](https://github.com/neosun100/DeepSeek-OCR-WebUI/issues)

---

**Made with â¤ï¸ by DeepSeek-OCR Team**
